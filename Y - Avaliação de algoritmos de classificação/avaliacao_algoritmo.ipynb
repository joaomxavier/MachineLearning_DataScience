{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Avaliação de Algoritmos de Classificação**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Matriz de confusão\n",
    "* Verdadeiro positivo e falso positivo\n",
    "* Precision e recall\n",
    "* Overfitting e underfitting\n",
    "* Validação cruzada\n",
    "* Tuning de parâmetros\n",
    "* Como testar e avaliar os algoritmos\n",
    "* Avaliação dos algoritmos com ANOVA e Tukey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Matriz de Confusão**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Auxilia na verificação dos erros e os acertos do algoritmo\n",
    "* O nome 'confusão' se refere a confusão que o classificador vai fazer em relação aos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <img src='imagens/matriz_confusao2.png'>\n",
    "</div>\n",
    "\n",
    "* 40 registros que eram da classe 'on time' foram classificados de forma correta, porém 7 registro 'on time' foram classificados de forma incorreta como 'late' e 3 registros como 'very late'.\n",
    "* 73 acertos → 72% → 72% é bom? precisamos analisar o cenário/contexto\n",
    "* 28 erros → 28%\n",
    "* É possível avaliar quais classes estamos classificando melhor e pior\n",
    "\n",
    "<div>\n",
    "    <img src='imagens/matriz_confusao.png'>\n",
    "</div>\n",
    "\n",
    "* Verdadeiro positivo: quando o classificador previu SIM e classe correta é SIM\n",
    "* Verdadeiro negativo: quando o classificador previu NÃO e a classe correta é NÃO\n",
    "* Falso positivo: quando o classificador previu SIM e a classe correta é NÃO\n",
    "* Falso negativo: quando o classificador previu NÃO e a classe correta é SIM\n",
    "* Accuracy score (taxa de acerto): (VP + VN) / total de registros\n",
    "* É necessário analisar a accuracy de cada classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Precision e Recall**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th></th>\n",
    "    <th>Fraude (SIM)</th>\n",
    "    <th>Legítima (NÃO)</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Fraude (SIM)</td>\n",
    "    <td>200 (VP)</td>\n",
    "    <td>50 (FN)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Legítima (NÃO)</td>\n",
    "    <td>50 (FP)</td>\n",
    "    <td>700 (VN)</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Precision`\n",
    "* Quando o modelo previu `SIM`, o quanto o modelo estava certo?\n",
    "    * VP / VP + FP → 200 / (200 + 50) → 0,8\n",
    "    * Quando o modelo prevê uma fraude, ele está correto em 80% dos casos\n",
    "    * Indica qual a precisão do modelo em classificar fraudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Recall`\n",
    "* Quando a classe é `SIM`, o quanto o modelo classificou corretamente?\n",
    "    * VP / VP + FN → 200 / (200 + 50) → 0,8\n",
    "    * O modelo indica corretamente 80% de todas as fraudes da base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Validação Cruzada**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Divisão da base de dados em teste e treinamento\n",
    "* As vezes, alguns registros que estão na base de testes seriam` ótimos previsores`, e então, seria muito melhor `ter esses registros na base de treinamento`. Isso acontece porque esses registros oferecem uma boa generalização das características dos dados, e com isso poderiam contribuir muito mais para o algoritmo se estivessem na base de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`K-fold Cross Validation`\n",
    "* É uma técnica de `validação cruzada` bastante utilizada que evita o problema citado acima (ter um registro na base de teste que é importante para fazer o treinamento)\n",
    "* Nesta abordagem, `todos os registros`, em algum momento, `são utilizados na base de teste e na base de treinamento`\n",
    "* K é um valor que o usuário define\n",
    "    * K = 10 é o padrão → quebra a base de dados em 10 pedaços\n",
    "* O dataset original é divido em K partes, onde em cada iteração, a base de dados de teste vai ser uma parte diferente do dataset original.\n",
    "* Para pegar o resultado final do percentual de acerto (`accuracy`) desse algoritmo, basta fazer uma média simples\n",
    "* Ex: 4-fold\n",
    "    * 1 iteração → 80%\n",
    "    * 2 iteração → 82%\n",
    "    * 3 iteração → 81%\n",
    "    * 4 iteração → 79%\n",
    "    * O acerto do algoritmo foi de 80,5%\n",
    "\n",
    "<div>\n",
    "    <img src='imagens/kfold.png'>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Underfitting e Overfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Overfitting é quando um modelo se ajusta muito bem ao conjunto de dados observado, porém se mostra ineficaz para prever novos resultados\n",
    "* O underfitting ocorre quando o modelo não consegue aprender as relações mais importantes entre as classes\n",
    "\n",
    "<div>\n",
    "    <img src='imagens/under_over.png'>\n",
    "</div>\n",
    "\n",
    "* Analogia:\n",
    "    * Na figura da esquerda (underfitting) temos um problema bastante complexo, que estamos tentando solucionar de forma simples, ou seja, estamos \"subestimando o problema\"\n",
    "    * Na figura da direita (overfitting) estamos utilizando muito recurso para resolver um problema simples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Underfitting**\n",
    "\n",
    "* Geralmente teremos resultados ruins na base de treinamento\n",
    "\n",
    "<div>\n",
    "    <img src='imagens/under.png'>\n",
    "</div>\n",
    "\n",
    "* Exemplo: na figura da esquerda temos uma parábola que representa o modelo ideal para separar os dados de forma adequada. E na figura da direita utiliza-se uma reta para realizar a separação dos dados, que claramente não é a melhor alternativa. Estamos 'subestimando' o problema ao utilizar uma reta para separação dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Overfitting**\n",
    "\n",
    "* Resultados `bons` na base de `treinamento` e resultados `ruins` na base de `teste`. Isso acontece pois o modelo se adapta demais aos dados que estão na base de treinamento.\n",
    "* \"Memorização\" dos dados\n",
    "\n",
    "<div>\n",
    "    <img src='imagens/over.png'>\n",
    "</div>\n",
    "\n",
    "* Exemplo: na figura da esquerda temos uma parábola que representa o modelo ideal para separar os dados de forma adequada. E na figura da direita estamos complicando o problema, que poderia ser solucionado de forma mais simples. O gráfico do lado direita está muito `adaptado` aos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (system)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2765143a23a2248ffb34e679751b02069243b5cebfc1f82e19b1c6754ea52f07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
